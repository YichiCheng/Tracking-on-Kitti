import os
import cv2
from ultralytics import YOLO
from ultralytics.utils import LOGGER
from deep_sort_realtime.deepsort_tracker import DeepSort
LOGGER.setLevel(50)  # åªä¿ç•™å…³é”®é”™è¯¯æ—¥å¿—

# å®šä¹‰ DeepSORT å‚æ•°
tracker = DeepSort(
    max_age=5,
    n_init=3,
    max_cosine_distance=0.2,
    nn_budget=None,
)

# COCO â†’ KITTI ç±»åˆ«å­—ç¬¦ä¸²æ˜ å°„
COCO_TO_KITTI = {2: "Car", 0: "Pedestrian"}  # Car â†’ "Car", Pedestrian â†’ "Pedestrian"

KITTI_PATH = "C:/yichi/kitti/training/image_02/"
SEQUENCES = sorted(os.listdir(KITTI_PATH))

# åˆå§‹åŒ– YOLOv8
model = YOLO("yolov8m.pt", verbose=False)



# åˆ›å»ºè¾“å‡ºç›®å½•
OUTPUT_PATH = "C:/yichi/PycharmProjects/YOLOv8_Project/TrackEval/data/trackers/kitti/kitti_2d_box_train/T2/data/"
VISUAL_OUTPUT_PATH = "C:/yichi/ds_visual_output/"
os.makedirs(OUTPUT_PATH, exist_ok=True)
os.makedirs(VISUAL_OUTPUT_PATH, exist_ok=True)

# éå†æ‰€æœ‰ sequence
for seq_id in SEQUENCES:
    seq_path = os.path.join(KITTI_PATH, seq_id)
    image_files = sorted(os.listdir(seq_path))

    track_results = []
    track_id_to_cls = {}  # è®°å½• track_id â†’ ç±»åˆ«åç§°

    for i, image_file in enumerate(image_files):
        image_path = os.path.join(seq_path, image_file)
        image = cv2.imread(image_path)

        if image is None:
            print(f"âš ï¸ Warning: Unable to load {image_path}, skipping...")
            continue

        # è·å–å›¾åƒå°ºå¯¸
        height, width = image.shape[:2]
        img_info = [height, width]
        img_size = (height, width)  # **ä¿æŒ YOLO è®­ç»ƒä½¿ç”¨çš„ 640x640**

        # è¿è¡Œ YOLO ç›®æ ‡æ£€æµ‹ï¼ˆä»…æ£€æµ‹ Car å’Œ Pedestrianï¼‰
        detections = []
        cls_list = []  # å­˜å‚¨ç±»åˆ«å­—ç¬¦ä¸²
        results = model(image, classes=[0, 2])

        # **è°ƒè¯•ä¿¡æ¯**
        print(f"ğŸŸ¢ Frame {i}: YOLO é¢„æµ‹å®Œæˆ")
        print(f"YOLO Model Config: {model.overrides}")  # æŸ¥çœ‹ imgsz
        print(f"Original Image Size: {img_info}")
        print(f"YOLO Detected Objects: {len(results[0].boxes)}")

        for r in results:
            boxes = r.boxes.xyxy.cpu().numpy()  # è·å–è¾¹ç•Œæ¡† (xyxy æ ¼å¼)
            scores = r.boxes.conf.cpu().numpy()  # è·å–ç½®ä¿¡åº¦
            classes = r.boxes.cls.cpu().numpy()  # è·å–ç±»åˆ«ç´¢å¼•

            for box, score, cls in zip(boxes, scores, classes):
                cls = int(cls)
                if cls not in COCO_TO_KITTI:
                    continue  # è¿‡æ»¤é Car/Pedestrian

                x1, y1, x2, y2 = map(int, box)

                detections.append([(x1, y1, x2 - x1, y2 - y1), float(score), COCO_TO_KITTI[cls]])
                print(f"Frame {i} detections: {detections}")

                cls_list.append(COCO_TO_KITTI[cls])  # è½¬æ¢ä¸º KITTI ç±»åˆ«åç§°

                # **å¯è§†åŒ– YOLO é¢„æµ‹æ¡†ï¼ˆè“è‰²ï¼‰**
                cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)
                cv2.putText(image, f"{COCO_TO_KITTI[cls]} {score:.2f}", (x1, y1 - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

        # è¿è¡Œ ds ç›®æ ‡è·Ÿè¸ª
        if len(detections) > 0:
            tracks = tracker.update_tracks(detections, frame=image)

        else:
            tracks = []

        print(f"ğŸ”¹ Frame {i}: {len(tracks)} objects tracked")

        # è®°å½•è·Ÿè¸ªç»“æœ
        frame_results = []
        for idx, t in enumerate(tracks):
            x1, y1, w, h = map(int, t.to_tlwh())  # âœ… DeepSORT æœŸæœ›çš„æ ¼å¼
            x2, y2 = x1 + w, y1 + h  # è®¡ç®—å³ä¸‹è§’åæ ‡
            track_id = t.track_id

            score = t.get_det_conf()# å¯èƒ½å­˜å‚¨ç½®ä¿¡åº¦çš„å±æ€§
            if score is None:
                score = 0.0  # è®¾ä¸ºé»˜è®¤å€¼ï¼Œé¿å… NoneType æ ¼å¼åŒ–é”™è¯¯

            # è·å–ç±»åˆ«åç§°ï¼Œé»˜è®¤è®¾ä¸º "Car"
            cls = track_id_to_cls.get(track_id, cls_list[idx] if idx < len(cls_list) else "Car")
            track_id_to_cls[track_id] = cls  # è®°å½•ç±»åˆ«

            frame_results.append([
                i, track_id, cls,
                0, 0, 0,
                x1, y1, x2, y2,
                -1, -1, -1,
                -1000, -1000, -1000,
                -10, score
            ])

            # **å¯è§†åŒ– ByteTrack è·Ÿè¸ªæ¡†ï¼ˆç»¿è‰²/çº¢è‰²ï¼‰**
            color = (0, 255, 0) if cls == "Car" else (0, 0, 255)
            cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
            cv2.putText(image, f"ID {track_id} {cls} {score:.2f}", (x1, y1 - 25),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

        track_results.append(frame_results)

        # **ä¿å­˜å¯è§†åŒ–ç»“æœ**
        visual_output_path = os.path.join(VISUAL_OUTPUT_PATH, f"{seq_id}_{image_file}")
        cv2.imwrite(visual_output_path, image)

    # **ä¿å­˜ Tracking ç»“æœ**
    output_txt = os.path.join(OUTPUT_PATH, f"{seq_id}.txt")
    with open(output_txt, "w") as f:
        for frame in track_results:
            for t in frame:
                f.write(" ".join(map(str, t)) + "\n")

    print(f"âœ… Finished sequence {seq_id}, results saved to {output_txt}")
